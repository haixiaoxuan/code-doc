{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8595, 0.2654],\n",
       "        [0.7043, 0.3573],\n",
       "        [0.8730, 0.6549],\n",
       "        [0.3220, 0.5844],\n",
       "        [0.8995, 0.4817]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建矩阵\n",
    "x = torch.empty(5, 3)\n",
    "x = torch.rand(5, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接传入数据\n",
    "torch.tensor([1, 2, 3])\n",
    "x.new_ones(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1838,  0.4668],\n",
       "        [-0.9403,  0.4541],\n",
       "        [-1.3573,  0.4860],\n",
       "        [-0.4210, -1.0530],\n",
       "        [ 0.9655,  1.6232]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(10).size()\n",
    "x.view(2, 5).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与numpy arr 互转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()\n",
    "import numpy as np\n",
    "torch.from_numpy(np.array([1, 2, 3]))\n",
    "\n",
    "# 转换之后共享同一块内存空间，如果tensor修改，则numpy跟着变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6069,  1.0407, -0.1315, -0.4904],\n",
       "        [-1.3172, -0.2398, -1.3741,  0.4628],\n",
       "        [ 1.3226, -0.1912, -0.9714,  0.0145]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4, requires_grad=True)   #表示可以对x进行求导\n",
    "x\n",
    "# 当设置 requires_grad=True 时，会开辟另外一块空间，x.grad 也是tensor，存放x的梯度值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3631, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(3, 4, requires_grad=True)\n",
    "t = x + b\n",
    "y = t.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()# 需要在最后一步标注一下\n",
    "\n",
    "y.backward(retain_graph=True) # 如果设置此参数，会把之前的梯度都累加起来，b.grad 返回的是累加梯度\n",
    "\n",
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, t.requires_grad\n",
    "# 虽然没有给t指定，但是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i for i in range(10)]).astype(np.float32).reshape(-1, 1)\n",
    "y = 2* x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinerRegressionModel(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class LinerRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinerRegressionModel, self).__init__()\n",
    "        # 全连接层\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "model = LinerRegressionModel(1, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 0.06582018733024597\n",
      "epoch 100, loss 0.03735992684960365\n",
      "epoch 150, loss 0.021205667406320572\n",
      "epoch 200, loss 0.012036464177072048\n",
      "epoch 250, loss 0.0068319677375257015\n",
      "epoch 300, loss 0.003877840470522642\n",
      "epoch 350, loss 0.002201108494773507\n",
      "epoch 400, loss 0.001249360153451562\n",
      "epoch 450, loss 0.000709150917828083\n",
      "epoch 500, loss 0.0004025031812489033\n",
      "epoch 550, loss 0.0002284664224134758\n",
      "epoch 600, loss 0.0001296770788030699\n",
      "epoch 650, loss 7.360892050201073e-05\n",
      "epoch 700, loss 4.1781571781029925e-05\n",
      "epoch 750, loss 2.3716762370895594e-05\n",
      "epoch 800, loss 1.346182580164168e-05\n",
      "epoch 850, loss 7.642683158337604e-06\n",
      "epoch 900, loss 4.337319751357427e-06\n",
      "epoch 950, loss 2.4614178073534276e-06\n",
      "epoch 1000, loss 1.3970043255540077e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    \n",
    "    # 需要将np.array 转为 tensor\n",
    "    inputs = torch.from_numpy(x)\n",
    "    labels = torch.from_numpy(y)\n",
    "    \n",
    "    # 每一次迭代梯度要清零\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新权重参数\n",
    "    optimizer.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch {0}, loss {1}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9978157],\n",
       "       [ 2.9981642],\n",
       "       [ 4.9985123],\n",
       "       [ 6.998861 ],\n",
       "       [ 8.999209 ],\n",
       "       [10.9995575],\n",
       "       [12.999907 ],\n",
       "       [15.000255 ],\n",
       "       [17.000603 ],\n",
       "       [19.000952 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.from_numpy(x).requires_grad_()).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的保存和读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 GPU 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要把数据传入到 cuda中\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "inputs = torch.from_numpy(x).to(device)\n",
    "labels = torch.from_numpy(y).to(device)\n",
    "\n",
    "# 1. 将模型传到 GPU。 \n",
    "# 2. 将数据传到 GPU。\n",
    "\n",
    "torch.ones_like(inputs, device=device)  # 将tensor直接定义到GPU\n",
    "label.to(\"cpu\", torch.double)   # 传到CPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见的tensor形式\n",
    "### 1. scalar\n",
    "### 2. vector\n",
    "### 3. matrix\n",
    "### 4. n-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.)\n",
      "42.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(42.)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1, 2, 3])\n",
    "m = torch.tensor([[1,2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [15, 22]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.matmul(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 9, 16]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  m * m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hub 模块\n",
    "### 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xiexiaoxuan/.cache\\torch\\hub\\v0.4.2.zip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2e6bbdaf34c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pytorch/vision:v0.4.2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\xiexiaoxuan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mlist\u001b[1;34m(github, force_reload)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepo_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m     \u001b[0mhub_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepo_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiexiaoxuan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiexiaoxuan\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiexiaoxuan\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_vision_v0.4.2/hubconf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'torch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malexnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdensenet121\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensenet169\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensenet201\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensenet161\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_vision_v0.4.2\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_vision_v0.4.2\\torchvision\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlsun\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSUN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSUNClass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetFolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCocoCaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCocoDetection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcifar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCIFAR100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstl10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTL10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_vision_v0.4.2\\torchvision\\datasets\\lsun.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "torch.hub.list(\"pytorch/vision:v0.4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(625.7877, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1], [2]], dtype=float))\n",
    "y = torch.from_numpy(np.array([3, 4], dtype=float))\n",
    "\n",
    "weight = torch.randn((1, 128), dtype=float, requires_grad=True)\n",
    "biases = torch.randn(128, dtype=float, requires_grad=True)\n",
    "weight2 = torch.randn((128, 1), dtype=float, requires_grad=True)\n",
    "biases2 = torch.randn(1, dtype=float, requires_grad=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "losses = []\n",
    "\n",
    "for i in range(1000):\n",
    "    hidden = x.mm(weight) + biases\n",
    "    hidden = torch.relu(hidden)\n",
    "    predictions = hidden.mm(weight2) + biases2\n",
    "    loss = torch.mean((predictions - y)**2)\n",
    "    losses.append(loss.data.numpy())\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"loss\", loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    weight.data.add_(- learning_rate * weight.grad.data)\n",
    "    biases.data.add_(- learning_rate * biases.grad.data)\n",
    "    weight2.data.add_(- learning_rate * weight2.grad.data)\n",
    "    biases2.data.add_(- learning_rate * biases2.grad.data)\n",
    "    \n",
    "    weight.grad.data.zero_()\n",
    "    biases.grad.data.zero_()\n",
    "    weight2.grad.data.zero_()\n",
    "    biases2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络比较简单的方法\n",
    "input_size = input_features.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "batch_size = 16\n",
    "\n",
    "my_nn = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_size),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size, output_size),\n",
    ")\n",
    "cost = torch.nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "for i in range(1000):\n",
    "    # mini-batch\n",
    "    for start in range(0, len(x), batch_size):\n",
    "        ...\n",
    "        prediction = my_nn(input_x)\n",
    "        loss = cost(prediction, output_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)# retain_graph 是否需要重复执行此代码\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy\n",
    "loss_func(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必须继承nn.Module 且在其构造函数中需要调用nn.Module的构造函数\n",
    "# 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "# Module 中的可学习参数可以通过 named_parameters() 或者 parameters() 返回迭代器\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_NN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 0.0172, -0.0332,  0.0010,  ..., -0.0230, -0.0283,  0.0023],\n",
      "        [-0.0085,  0.0022,  0.0139,  ...,  0.0103, -0.0030, -0.0200],\n",
      "        [ 0.0181,  0.0345,  0.0235,  ...,  0.0194, -0.0295,  0.0158],\n",
      "        ...,\n",
      "        [-0.0234,  0.0125,  0.0062,  ...,  0.0277, -0.0077,  0.0292],\n",
      "        [-0.0233,  0.0351,  0.0119,  ..., -0.0062, -0.0264,  0.0169],\n",
      "        [-0.0034, -0.0234,  0.0243,  ...,  0.0256,  0.0046, -0.0133]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([-0.0128,  0.0149,  0.0081, -0.0106,  0.0272, -0.0277,  0.0066, -0.0211,\n",
      "         0.0080,  0.0029, -0.0234,  0.0152, -0.0098,  0.0317,  0.0245, -0.0321,\n",
      "         0.0267, -0.0114, -0.0148,  0.0166, -0.0252,  0.0274, -0.0037,  0.0205,\n",
      "        -0.0245, -0.0086,  0.0154,  0.0152,  0.0231,  0.0137,  0.0216, -0.0062,\n",
      "         0.0272,  0.0278, -0.0157, -0.0343, -0.0064, -0.0219, -0.0137, -0.0030,\n",
      "        -0.0227,  0.0336,  0.0063,  0.0321, -0.0294, -0.0067, -0.0258, -0.0274,\n",
      "         0.0051,  0.0318, -0.0242, -0.0159, -0.0196, -0.0248, -0.0303,  0.0022,\n",
      "         0.0322, -0.0230,  0.0349, -0.0119, -0.0248, -0.0102,  0.0281, -0.0003,\n",
      "         0.0349,  0.0288, -0.0318,  0.0322,  0.0056, -0.0229, -0.0089,  0.0160,\n",
      "         0.0057, -0.0103,  0.0260,  0.0293,  0.0015, -0.0057,  0.0117,  0.0032,\n",
      "         0.0237, -0.0003,  0.0089,  0.0077,  0.0326,  0.0152,  0.0206,  0.0308,\n",
      "         0.0340, -0.0115, -0.0330, -0.0115, -0.0220, -0.0122, -0.0168,  0.0150,\n",
      "         0.0334,  0.0223, -0.0164,  0.0233,  0.0092, -0.0285,  0.0026,  0.0203,\n",
      "        -0.0329,  0.0030, -0.0144, -0.0318, -0.0331,  0.0340,  0.0072, -0.0230,\n",
      "        -0.0097,  0.0197,  0.0236, -0.0287,  0.0241, -0.0135, -0.0132, -0.0307,\n",
      "        -0.0248, -0.0169, -0.0161,  0.0190,  0.0022,  0.0043,  0.0328, -0.0288],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[-0.0546,  0.0195,  0.0534,  ...,  0.0210,  0.0135,  0.0450],\n",
      "        [-0.0427, -0.0146, -0.0716,  ..., -0.0855,  0.0678, -0.0470],\n",
      "        [ 0.0633,  0.0574,  0.0246,  ..., -0.0364,  0.0404,  0.0677],\n",
      "        ...,\n",
      "        [-0.0269,  0.0004,  0.0470,  ...,  0.0514, -0.0065, -0.0545],\n",
      "        [ 0.0173,  0.0067, -0.0136,  ...,  0.0248,  0.0453,  0.0722],\n",
      "        [ 0.0053, -0.0430, -0.0674,  ..., -0.0532, -0.0820,  0.0749]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([-0.0604,  0.0648,  0.0867,  0.0280,  0.0151,  0.0467,  0.0279,  0.0645,\n",
      "        -0.0479,  0.0230, -0.0693, -0.0326, -0.0661, -0.0242,  0.0414, -0.0219,\n",
      "         0.0783, -0.0606, -0.0454,  0.0296, -0.0775, -0.0541,  0.0458,  0.0433,\n",
      "         0.0225, -0.0512, -0.0705, -0.0293, -0.0334,  0.0324,  0.0823, -0.0844,\n",
      "        -0.0400, -0.0255, -0.0596, -0.0775,  0.0010,  0.0646, -0.0101,  0.0399,\n",
      "         0.0335, -0.0768, -0.0881, -0.0410, -0.0311,  0.0667,  0.0672, -0.0603,\n",
      "        -0.0584,  0.0120, -0.0472,  0.0688,  0.0060,  0.0253, -0.0011, -0.0229,\n",
      "        -0.0264, -0.0451,  0.0841,  0.0004, -0.0323,  0.0676, -0.0672, -0.0281,\n",
      "         0.0795,  0.0252,  0.0603, -0.0544, -0.0003,  0.0875, -0.0099,  0.0421,\n",
      "        -0.0050, -0.0319,  0.0551,  0.0830,  0.0339, -0.0269,  0.0605, -0.0806,\n",
      "        -0.0468, -0.0065,  0.0136, -0.0064,  0.0238,  0.0748, -0.0879, -0.0635,\n",
      "         0.0226, -0.0689,  0.0653,  0.0148, -0.0668,  0.0766, -0.0620, -0.0508,\n",
      "        -0.0486, -0.0205,  0.0028,  0.0834,  0.0123, -0.0654,  0.0439, -0.0515,\n",
      "         0.0236,  0.0665, -0.0016, -0.0430,  0.0467, -0.0132, -0.0073, -0.0220,\n",
      "        -0.0529,  0.0780,  0.0766,  0.0857, -0.0322, -0.0872, -0.0040,  0.0624,\n",
      "        -0.0031, -0.0175,  0.0297,  0.0566, -0.0121, -0.0320, -0.0186,  0.0322,\n",
      "        -0.0416, -0.0151, -0.0777,  0.0846,  0.0864,  0.0775,  0.0637,  0.0447,\n",
      "        -0.0477,  0.0586,  0.0593,  0.0764,  0.0418, -0.0369, -0.0687,  0.0395,\n",
      "         0.0541, -0.0599, -0.0609, -0.0610,  0.0347, -0.0064,  0.0874,  0.0864,\n",
      "        -0.0880,  0.0876,  0.0152,  0.0580, -0.0051,  0.0125,  0.0513, -0.0129,\n",
      "         0.0295, -0.0525,  0.0331, -0.0242,  0.0055, -0.0033, -0.0711, -0.0579,\n",
      "        -0.0783,  0.0224,  0.0779,  0.0125,  0.0603,  0.0393,  0.0011,  0.0290,\n",
      "        -0.0518, -0.0192,  0.0713, -0.0724,  0.0416,  0.0597, -0.0835, -0.0637,\n",
      "        -0.0809,  0.0747, -0.0394,  0.0122, -0.0128, -0.0522,  0.0313,  0.0076,\n",
      "        -0.0714, -0.0313, -0.0871,  0.0318, -0.0344,  0.0013,  0.0203, -0.0241,\n",
      "        -0.0571,  0.0561,  0.0776,  0.0459, -0.0461, -0.0234,  0.0793, -0.0129,\n",
      "        -0.0033,  0.0675,  0.0309,  0.0748,  0.0116, -0.0466,  0.0652,  0.0086,\n",
      "        -0.0141,  0.0365,  0.0259,  0.0652,  0.0217, -0.0549,  0.0689, -0.0468,\n",
      "         0.0029, -0.0351, -0.0346,  0.0883, -0.0666,  0.0793, -0.0588,  0.0292,\n",
      "         0.0587, -0.0502, -0.0204,  0.0208,  0.0718,  0.0789,  0.0123, -0.0729,\n",
      "         0.0452, -0.0804,  0.0563, -0.0560, -0.0169, -0.0503, -0.0838, -0.0837,\n",
      "        -0.0310, -0.0059, -0.0060, -0.0714, -0.0094, -0.0063, -0.0827,  0.0421],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[-0.0542,  0.0134,  0.0313,  ..., -0.0583, -0.0016,  0.0031],\n",
      "        [ 0.0080, -0.0069,  0.0054,  ...,  0.0124,  0.0554,  0.0588],\n",
      "        [-0.0220, -0.0020,  0.0029,  ...,  0.0148, -0.0367, -0.0349],\n",
      "        ...,\n",
      "        [ 0.0591, -0.0614, -0.0199,  ..., -0.0544, -0.0012,  0.0443],\n",
      "        [ 0.0237,  0.0256,  0.0389,  ...,  0.0242, -0.0481,  0.0025],\n",
      "        [-0.0514, -0.0427,  0.0282,  ..., -0.0143, -0.0607, -0.0076]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0454, -0.0619, -0.0596,  0.0425,  0.0169, -0.0036,  0.0457,  0.0209,\n",
      "        -0.0566,  0.0493], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter, parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x, y)\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "# 一般在训练模型的时候加上 model.train(), 这样会正常使用 batch Normalization 和 dropout\n",
    "# 测试的时候一般选择 model.eval()， 这样就不会使用 batch normalization 和 dropout\n",
    "\n",
    "for step in range(steps):\n",
    "    model.train()\n",
    "    for x_train, y_train in train_dl:\n",
    "        loss_batch(...)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, nums = zip(*[loss_batch(...) for x_valid, y_valid in valid_dl])\n",
    "    valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络模块构建\n",
    "#### 卷积最后结果是一个特征图，需要把图转换成向量才能做分类或者回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            F.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(s.size(0), -1)\n",
    "        output = self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'ReLU'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-3e400e6c6fbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-1f771673f51b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             ),\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'ReLU'"
     ]
    }
   ],
   "source": [
    "net = CNN()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    \n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss_num = loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_num.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target)\n",
    "        train_right.append(right)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, 预训练model，transform 数据转换增强...\n",
    "pip install torchversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
