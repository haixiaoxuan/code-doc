#! -*-coding=utf8-*-

###############################
# import modin.pandas as pd 	pandas的多核版本
###############################


import pandas as pd
from pandas import Series
import numpy as np

pd.set_option('display.max_columns', 100000)  # a就是你要设置显示的最大列数参数
pd.set_option('display.max_rows', 100000)  # b就是你要设置显示的最大的行数参数
pd.set_option('display.width', 100000)  # x就是你要设置的显示的宽度，防止轻易换行


pandas 数据类型
	float16, float32, float64
	int8, int16, int32, int64, uint8, uint16, uint32, uint64
	datatime64(八个字节)
	bool
	object(可变字节)


""" 
series 常用方法：
	value_count()
	pd.to_numeric    将series的类型转为数字

df 常用函数
    平均值 ：           mean
    分组：             groupby		之后可以直接 head(10) ,分组之后可以使用聚合函数，如果不希望分组列变为索引列，可以指定as_index=False
    统计指标：          describe   统计内容（std标准差，count, count(distinct), max...）
    转置：             transpose
    去重并count        nunique
    分组并count        value_counts
    对每个元素应用函数   apply
    按照某一列排序       sort_values() 
    判断空值            isnull
	判断非空值			notnull
    设置值              set_value()
	将某一列设为index					df.set_index("date")
	基本信息			info()
	替换				replace()
	统计信息			describe()
	查询				query()			示例： dftrain_raw.query('Survived == 0')
	可以使用函数对两个列进行操作返回一个新的列  add(df["col1"],df["col2"])
	
df 常用属性
    index
    columns       可以直接赋值，赋值之后列名就会变为相应的值
    values        转变为 np中的array形式
	dtypes		  各列的类型
pd 常用函数
	日期转换函数 pd.to_datetime()..
    多个df叠加  concat
    合并函数    merge       (left, right, how='inner', on='Key')   也可以在 on 属性传入过个列名进行合并
			pd.merge(df1,df2,left_index=True, right_index=True) 按照索引进行合并
    关联        join      和merge不同，join采用索引进行关联
    去重        unique
	转换		DataFrame(arr)	将arr 转换为df，也可以将字典转换为 df DataFrame({"a":[1,2,3],"b":[4,5,6]})
	one-hot编码		get_dummies		可以将某一列进行编码或者某几列， pd.get_dummies(dfdata['Pclass'])
    判断是否为空	pd.isna		返回布尔值
	
"""

# read_csv 参数
pd.read_csv()
	dtype={"name": object, "age": uint8}	可以在读入之前为每一列指定数据类型
	parse_dates=['date']					可以指定需要解析为date数据类型的列
	infer_datetime_format=True


# 一维 Series
d={"name":"xiaoxuan","age":18}
l=[1,2]
# index 参数可以省略，会有默认的 0 1 2 作为index
# 如果存字典的话就默认把 key 作为 index
series = pd.Series(d)
print(series)

# 二维 DataFrame
df = {"name":Series(["xiaoxuan1","xiaoxuan2","xiaoxuan3"],[7,8,9]),
      "age":Series([18,19,20],[7,8,10])}
df = pd.DataFrame(df)
# 返回一列和返回多列
df["name"] ; df[["name","age"]]
# 增加列
df["weight"] = Series([41,42,43],[7,8,9])
# 删除行 axis=0 代表行, 如果执行的话并不会真正删除（inplace=True 才会真正删除）
df.drop(7,axis=0)

# 显示某一行,按照行索引 (iloc 参数为要显示的行号)
df.loc[7] ; df.loc[[7,8]] ; df.iloc[1]	; df.iloc[:,1:]	可以当成 array 进行切分
df.loc["name"] = df.apply(.., axis=0)	增加一行
df.loc[(df["age"]>100 & df["score"] < 100),:]
df.loc[df[xx] == xx, column]        # 根据条件只拿指定的列或者只改变指定的列名

df.ix[1,"name"] 拿出第一行的name列   df.ix[1:7,["name","age"]]
# 表示 行索引为7，的name列
df.loc[7,"name"] ; df.loc[[7,8],["name","age"]]
# 条件筛选
df[df["age"]>19]  ; df[(df["age"]>18) & (df["weight"]==43) ]
# 重置索引 (也存在 inplace 参数)
df.reset_index()
df.set_index()  # 将某一列设为索引
# 多级索引
myIndex = pd.MultiIndex.from_tuples(list(zip([1, 1, 1], ["a", "b", "c"])))
pd.DataFrame(np.random.randn(3,4),myIndex,columns=["A","B","C","D"])


# 类别数据处理办法
b=pd.Categorical(a[1])	此时，b有属性 codes 和 categories
a[1]=a[1].astype("category")	此时，a[1] 为 category类型，使用 Series属性.cat.codes 和 .cat.categories (分别返回category之后的数值列和 index_mapping)
			如果 count(distinct) 数量相对于整体记录数很少，就可以使用 category来减少内存占用
			缺点: 无法进行 min max 等计算


# 数据处理
    # 1 空值处理 np.nan
df.dropna(axis=0)   # 删除存在一个或多个空值的行 subset=[""]此参数可以指定那些列为空才被删除
df.drop_duplicates()	# 删除重复值，默认删除完全重复的行，可以使用subset指定列，可以使用keep参数指定保留哪一行
df.fillna("a")      # 将所有空值替换为 a
df.fillna(value={"A":df.mean()["A"]})   # 将 A 列的空值替换为 A列的均值


# 数据透视表
pd.pivot_table(df,values='score',index="name")    # values 表示需要汇总的数据所在的列 index 表示按该列进行分组索引 column 表示最后的结果应该改按该列进行分列
pd.crosstab()

# 读取csv数据
pd.read_csv
df.to_csv()

pd.read_excel
df.to_excel

pd.read_table()	# 读取文本
pd.read_json()	# 读取json

# 数据预处理
# categorical  实际上是计算一个列表型数据中的类别数，即不重复项，它返回的是一个CategoricalDtype 类型的对象，相当于在原来数据上附加上类别信息 ，
# 具体的类别可以通过和对应的序号可以通过  codes  和 categories 来查看：
res=pd.Categorical(["a","a","b"])
print(res.codes)      #  [0 0 1]
print(res.categories) #  ['a', 'b']

# 分位数
df[0].quantile([0.1,0.2])	# 将数据排序然后分为三段，第一段所占比例为0.1，第二段也是 0.1，第三段为 0.8
pd.qcut([1,2,3,4,5,6,7,8,9,10],q=3,labels=False)	# 将数据排序，并使用 0，1，2....的标签对数据进行编号
pd.cut(x=df[""],bins=[10,20,30,40], label=["低","中","中","高"])	 bins也可以指定数字（分为几组）

# rank 排序函数
df.group("user_id").prob.rank()     # 对每个user的prob进行排序，相当与 row_number()，如果有相同的值，可以选择 method='average'|'max'|'min'|'dense'|'first'
                                    https://blog.csdn.net/code_porter/article/details/86517233

# argpartition
    a = np.array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])
    print(np.argpartition(a, 4)) #将数组a中所有元素（包括重复元素）从小到大排列，比第5大的元素小的放在前面，大的放在后面，输出新数组索引  [6 9 4 3 7 2 1 5 8 0]
    a[np.argpartition(a, 4)]     #输出新数组索引对应的数组  array([0, 0, 3, 3, 4, 4, 4, 9, 6, 9])

    np.argpartition(a, -5)      倒数第五个


# 得到df的大小
df.info(memory_usage='deep')	# 显示数据类型以及df所占的大小

# 通过列类型来选择列
df.select_dtypes(include=['object'])


# 使用数字类型优化内存
df.apply(pd.to_numeric,downcast='unsigned')	# 可以将数字类型向下转型，变为无符号类型


# datatime类型 使用
pandas.to_datetime(xx, format="%Y%m%d")		# format 为最终显示的格式, datatime为八个字节的大小


# map apply applymap
map是 Series的函数，DataFrame中没有map，将自定义函数应用于每个元素
apply()将一个函数作用于DataFrame中的每个行或者列， 例 df["data1", "data2"].apply(lambda x: s.sum(), axis=1)
applymap() 将一个函数作用于 DataFrame中的每一个元素

经典用法: data["user_id"].map() 传入字典, 对 user_id 进行映射


df["name"].str      可以使用字符串操作对name列进行处理


############################################################################

画图：
	>>> import matplotlib.pyplot as plt
	>>> import seaborn as sns
	>>> sns.set_style('whitegrid')		# 网格线
	>>> fig, ax = plt.subplots()
	>>> biz_df['x'].hist(ax=ax, bins=100)	# 将x分为100份
	>>> ax.set_yscale('log')		# 设置 y 的显示方式
	>>> ax.tick_params(labelsize=14)
	>>> ax.set_xlabel('x', fontsize=14)
	>>> ax.set_ylabel('y', fontsize=14)
	

使用Pandas来画图
	Series.plot()	
	位置参数：kind,    bar 柱状图；hist 柱状图； density 曲线图
			  figsize	元组(10,10)
			  fontsize	10
			  rot		旋转
	示例：
	ax = dftrain_raw['Survived'].value_counts().plot(kind = 'bar', figsize = (12, 8), fontsize=15, rot = 0)
	ax = dftrain_raw['Age'].plot(kind = 'hist', bins = 20, color= 'purple', figsize = (12,8), fontsize=15)
	
	ax = dftrain_raw.query('Survived == 0')['Age'].plot(kind = 'density', figsize = (12,8), fontsize=15)
	dftrain_raw.query('Survived == 1')['Age'].plot(kind = 'density', figsize = (12,8), fontsize=15)
	ax.legend(['Survived==0','Survived==1'], fontsize = 12)	# 指定标题
	ax.set_ylabel('Density', fontsize = 15)
	ax.set_xlabel('Age', fontsize = 15)



############################################################################
# 随机抽取样本数据
pd.read_csv("path", skiprows=lambda x: x>0 and np.random.rand() > 0.01)
# replace 做数据清洗, 替换掉脏字符a b为空
df["col"]=df["col"].replace("[a,b]", "", regex=True).astype("float")
# 行转列
df.melt....




